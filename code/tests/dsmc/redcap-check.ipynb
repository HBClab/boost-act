{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb22edeb-3392-4c91-9b55-95866759218c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        ID        Date                  filename\\n0     1005  2022-05-10  1005 (2022-05-10)RAW.csv\\n1     1023  2022-04-30  1023 (2022-04-30)RAW.csv\\n2     1027  2022-04-26  1027 (2022-04-26)RAW.csv\\n3     1016  2022-03-23  1016 (2022-03-23)RAW.csv\\n4      994  2022-05-13   994 (2022-05-13)RAW.csv\\n...    ...         ...                       ...\\n1152   584  2018-09-15   584 (2018-09-15)RAW.csv\\n1153   584  2018-10-16   584 (2018-10-16)RAW.csv'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "\n",
    "class ID_COMPARISONS:\n",
    "    \n",
    "    def __init__(self, daysago=None) -> None:\n",
    "       self.token = 'DE4E2DB72778DACA9B8848574107D2F5'\n",
    "       self.INT_DIR = '/Volumes/vosslabhpc/Projects/BOOST/InterventionStudy/3-experiment/data/act-int-test'\n",
    "       self.OBS_DIR = '/Volumes/vosslabhpc/Projects/BOOST/ObservationalStudy/3-experiment/data/act-obs-test'\n",
    "       self.daysago = daysago\n",
    "       logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "    def compare_ids(self):\n",
    "        \"\"\"\n",
    "        Pulls all files from RDSS\n",
    "        Pulls the list from RedCap\n",
    "        Compares IDs and returns a dictionary with two keys:\n",
    "          - 'matches': normal matches mapping boost_id to a list of dicts (filename, labID, date)\n",
    "          - 'duplicates': a list of dictionaries each with lab_id, boost_id, filenames (list), and dates (list)\n",
    "        \"\"\"\n",
    "        # Retrieve the RedCap report and duplicates from report\n",
    "        report, report_duplicates = self._return_report()\n",
    "        # Retrieve the full RDSS file list and duplicate files merged with duplicates from report\n",
    "        rdss, file_duplicates = self._rdss_file_list(report_duplicates, self.daysago)\n",
    "\n",
    "        # Initialize the result dictionary for normal (non-duplicate) matches\n",
    "        result = {}\n",
    "\n",
    "        # Iterate over the rows in the cleaned RedCap report\n",
    "        for _, row in report.iterrows():\n",
    "            boost_id = str(row['boost_id'])\n",
    "            lab_id = str(row['lab_id'])\n",
    "            \n",
    "            # Find matching files in the RDSS list\n",
    "            rdss_matches = rdss[rdss['ID'] == lab_id]\n",
    "            if not rdss_matches.empty:\n",
    "                if boost_id not in result:\n",
    "                    result[boost_id] = []\n",
    "                for _, match_row in rdss_matches.iterrows():\n",
    "                    result[boost_id].append({\n",
    "                        'filename': match_row['filename'],\n",
    "                        'labID': lab_id,\n",
    "                        'date': match_row['Date']\n",
    "                    })\n",
    "        \n",
    "        # Process duplicates into the desired structure.\n",
    "        duplicates_dict = []\n",
    "        if not file_duplicates.empty:\n",
    "            # Group by lab_id and boost_id; each group represents one duplicate combination.\n",
    "            grouped = file_duplicates.groupby(['lab_id', 'boost_id'])\n",
    "            for (lab_id, boost_id), group in grouped:\n",
    "                duplicates_dict.append({\n",
    "                    'lab_id': lab_id,\n",
    "                    'boost_id': boost_id,\n",
    "                    'filenames': group['filename'].tolist(),\n",
    "                    'dates': group['Date'].tolist()\n",
    "                })\n",
    "        else:\n",
    "            logging.info(\"Found no duplicates.\")\n",
    "\n",
    "        return {'matches': result, 'duplicates': duplicates_dict}, report\n",
    "\n",
    "    def _return_report(self):\n",
    "        \"\"\"\n",
    "        pulls the id report from the rdss via redcap api.\n",
    "        reads the report as a dataframe.\n",
    "        checks for boost_ids that are associated with multiple lab_ids, logs a critical error,\n",
    "        and removes these rows from the dataframe.\n",
    "        separates duplicate rows (based on any column) from the cleaned data.\n",
    "        \n",
    "        returns:\n",
    "            df_cleaned: dataframe with duplicates removed and problematic boost_ids excluded\n",
    "            duplicate_rows: dataframe of duplicate rows\n",
    "        \"\"\"\n",
    "        url = 'https://redcap.icts.uiowa.edu/redcap/api/'\n",
    "        data = {\n",
    "            'token': self.token,\n",
    "            'content': 'report',\n",
    "            'report_id': 43327,\n",
    "            'format': 'csv'\n",
    "        }\n",
    "        r = requests.post(url, data=data)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"error! status code is {r.status_code}\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        df = pd.read_csv(StringIO(r.text))\n",
    "        \n",
    "        # identify boost_ids associated with multiple lab_ids.\n",
    "        boost_id_counts = df.groupby('boost_id')['lab_id'].nunique()\n",
    "        problematic_boost_ids = boost_id_counts[boost_id_counts > 1].index.tolist()\n",
    "        \n",
    "        if problematic_boost_ids:\n",
    "            logging.critical(f\"found boost_id(s) with multiple lab_ids: {', '.join(map(str, problematic_boost_ids))}. \"\n",
    "                            \"these entries will be removed from processing.\")\n",
    "            df = df[~df['boost_id'].isin(problematic_boost_ids)]\n",
    "        \n",
    "        # identify and separate duplicate rows based on any column.\n",
    "        duplicate_rows = df[df.duplicated(keep=False)]\n",
    "        df_cleaned = df.drop_duplicates(keep=False)\n",
    "        \n",
    "        if not duplicate_rows.empty:\n",
    "            logging.info(f\"duplicate rows found:\\n{duplicate_rows}\")\n",
    "        \n",
    "        return df_cleaned, duplicate_rows\n",
    "\n",
    "    def _rdss_file_list(self, duplicates, daysago=None):\n",
    "        \"\"\"\n",
    "        extracts the first string before the space and the date from filenames ending with .csv\n",
    "        in the specified folder and stores them in a dataframe.\n",
    "        \n",
    "        Also, merges the file list with duplicate report entries based on lab_id.\n",
    "        \n",
    "        Returns:\n",
    "            df: DataFrame of all file entries\n",
    "            merged_df: DataFrame of file entries that match duplicate lab_ids from the report\n",
    "        \"\"\"\n",
    "        extracted_data = []\n",
    "\n",
    "        # Loop through all files in the rdss_dir folder.\n",
    "        rdss_dir = '/mnt/rdss/VossLab/Repositories/Accelerometer_Data'\n",
    "        for filename in os.listdir(rdss_dir):\n",
    "            if filename.endswith('.csv'):\n",
    "                try:\n",
    "                    base_name = filename.split(' ')[0]  # Extract lab_id\n",
    "                    date_part = filename.split('(')[1].split(')')[0]  # Extract date\n",
    "                    extracted_data.append({'ID': base_name, 'Date': date_part, 'filename': filename})\n",
    "                except IndexError:\n",
    "                    print(f\"Skipping file with unexpected format: {filename}\")\n",
    "\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "            if daysago:\n",
    "                cutoff_date = datetime.today() - timedelta(days=daysago)\n",
    "                df = df[df['Date'] >= cutoff_date]  # Filter files within the last `daysago` days\n",
    "            else:\n",
    "                df = df[df['Date'] >= '2024-08-05']  # Filter out rows before the threshold date\n",
    "\n",
    "        # Filter the file list to only include rows where ID is in the duplicate report (if any)\n",
    "        if not duplicates.empty:\n",
    "            matched_df = df[df['ID'].isin(duplicates['lab_id'])]\n",
    "            # Merge with the duplicates to bring in boost_id information from the report\n",
    "            merged_df = matched_df.merge(duplicates, left_on='ID', right_on='lab_id')\n",
    "        else:\n",
    "            merged_df = pd.DataFrame()\n",
    "\n",
    "        return df, merged_df\n",
    "\n",
    "\n",
    "# REPORT EXAMPLE\n",
    "\"\"\"  lab_id  boost_id\n",
    "0     1023      8022\n",
    "1     1043      7062\n",
    "2     1093      6011\n",
    "3     1097      6012\n",
    "4     1098      6013\n",
    "..     ...       ...\n",
    "90    1192      7058\n",
    "91    1193      7059\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# RDSS EXAMPLE\n",
    "\"\"\"        ID        Date                  filename\n",
    "0     1005  2022-05-10  1005 (2022-05-10)RAW.csv\n",
    "1     1023  2022-04-30  1023 (2022-04-30)RAW.csv\n",
    "2     1027  2022-04-26  1027 (2022-04-26)RAW.csv\n",
    "3     1016  2022-03-23  1016 (2022-03-23)RAW.csv\n",
    "4      994  2022-05-13   994 (2022-05-13)RAW.csv\n",
    "...    ...         ...                       ...\n",
    "1152   584  2018-09-15   584 (2018-09-15)RAW.csv\n",
    "1153   584  2018-10-16   584 (2018-10-16)RAW.csv\"\"\"\n",
    "\n",
    "# TOKEN FOR REFERENCE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2b57858-f8ba-45e2-a348-2cff64d9f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = ID_COMPARISONS(daysago=499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "010883f2-2107-4fc6-9258-ab839ae86e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:37:35,204 - CRITICAL - found boost_id(s) with multiple lab_ids: 7023. these entries will be removed from processing.\n",
      "2025-08-01 10:37:49,049 - INFO - Found no duplicates.\n"
     ]
    }
   ],
   "source": [
    "matches, report = I.compare_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32ba158c-2d71-4ee8-90e3-7b69182455f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a40aad2e-2c7d-428d-b9d2-c97a42bcf947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "num_subjects = sum(1 for sid in matches['matches'] if sid.startswith('8'))\n",
    "print(num_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "458d4b74-8b19-43d1-acb3-32600aac443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int = pd.read_csv('./int.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea5c06d9-992b-4f95-a221-08612d0ee8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub-8024</th>\n",
       "      <th>sub-8016</th>\n",
       "      <th>sub-8037</th>\n",
       "      <th>sub-8005</th>\n",
       "      <th>sub-8008</th>\n",
       "      <th>sub-8011</th>\n",
       "      <th>sub-8023</th>\n",
       "      <th>sub-8015</th>\n",
       "      <th>sub-8006</th>\n",
       "      <th>sub-8018</th>\n",
       "      <th>sub-8003</th>\n",
       "      <th>sub-8036</th>\n",
       "      <th>sub-8004</th>\n",
       "      <th>sub-8019</th>\n",
       "      <th>sub-8021</th>\n",
       "      <th>sub-8035</th>\n",
       "      <th>sub-8026</th>\n",
       "      <th>sub-8014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sessions</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_days</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weekdays</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekends</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sub-8024  sub-8016  sub-8037  sub-8005  sub-8008  sub-8011  \\\n",
       "0    sessions         1         2         1         2         2         2   \n",
       "1  total_days         9        18         9        18        16        18   \n",
       "2    weekdays         5        14         6        14        13        12   \n",
       "3    weekends         4         4         3         4         3         6   \n",
       "\n",
       "   sub-8023  sub-8015  sub-8006  sub-8018  sub-8003  sub-8036  sub-8004  \\\n",
       "0         1         1         2         2         2         1         2   \n",
       "1         9         9        18        18        15         9        12   \n",
       "2         7         7        11        14         9         7         6   \n",
       "3         2         2         7         4         6         2         6   \n",
       "\n",
       "   sub-8019  sub-8021  sub-8035  sub-8026  sub-8014  \n",
       "0         2         1         1         2         1  \n",
       "1        18         8         9        18         9  \n",
       "2        14         7         7        13         7  \n",
       "3         4         1         2         5         2  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d345e994-4c67-4a5a-b616-69abab6d294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 19)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6b16227-d091-42be-a4a2-595bcf68831d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab_id</th>\n",
       "      <th>boost_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023</td>\n",
       "      <td>8022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043</td>\n",
       "      <td>7062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1051</td>\n",
       "      <td>7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1093</td>\n",
       "      <td>6011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1402</td>\n",
       "      <td>7205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1403</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1404</td>\n",
       "      <td>7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1405</td>\n",
       "      <td>7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1406</td>\n",
       "      <td>7209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lab_id boost_id\n",
       "0      1023     8022\n",
       "1      1040     7183\n",
       "2      1043     7062\n",
       "3      1051     7146\n",
       "4      1093     6011\n",
       "..      ...      ...\n",
       "266    1402     7205\n",
       "267    1403     7206\n",
       "268    1404     7207\n",
       "269    1405     7208\n",
       "270    1406     7209\n",
       "\n",
       "[269 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e504fcd5-cfe2-4900-87d4-cbb7842b68f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8022\n",
       "29     8001\n",
       "30     8002\n",
       "31     8003\n",
       "32     8004\n",
       "33     8007\n",
       "34     8006\n",
       "39     8005\n",
       "50     8008\n",
       "53     8009\n",
       "54     8010\n",
       "55     8011\n",
       "58     8012\n",
       "59     8013\n",
       "60     8014\n",
       "62     8015\n",
       "63     8016\n",
       "65     8017\n",
       "67     8018\n",
       "68     8019\n",
       "69     8020\n",
       "70     8021\n",
       "84     8023\n",
       "85     8024\n",
       "87     8025\n",
       "93     8026\n",
       "97     8028\n",
       "98     8029\n",
       "99     8030\n",
       "100    8031\n",
       "117    8032\n",
       "138    8033\n",
       "139    8034\n",
       "140    8035\n",
       "162    8036\n",
       "165    8037\n",
       "174    8038\n",
       "180    8039\n",
       "182    8043\n",
       "183    8040\n",
       "184    8045\n",
       "185    8041\n",
       "186    8042\n",
       "196    8046\n",
       "201    8047\n",
       "202    8048\n",
       "206    8050\n",
       "208    8051\n",
       "210    8052\n",
       "211    8053\n",
       "212    8054\n",
       "234    8055\n",
       "237    8056\n",
       "238    8057\n",
       "239    8058\n",
       "240    8059\n",
       "241    8060\n",
       "259    8061\n",
       "Name: boost_id, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = report[report['boost_id'].astype(str).str.startswith('8')]\n",
    "boost_ids = report['boost_id']\n",
    "boost_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c84945e0-eacd-4bea-bbed-9f14afb000f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8022',\n",
       " '8001',\n",
       " '8002',\n",
       " '8003',\n",
       " '8004',\n",
       " '8006',\n",
       " '8005',\n",
       " '8008',\n",
       " '8011',\n",
       " '8012',\n",
       " '8014',\n",
       " '8015',\n",
       " '8016',\n",
       " '8017',\n",
       " '8018',\n",
       " '8019',\n",
       " '8020',\n",
       " '8021',\n",
       " '8023',\n",
       " '8024',\n",
       " '8026',\n",
       " '8030',\n",
       " '8032',\n",
       " '8035',\n",
       " '8036',\n",
       " '8037',\n",
       " '8038',\n",
       " '8039',\n",
       " '8040',\n",
       " '8042',\n",
       " '8046',\n",
       " '8047',\n",
       " '8048',\n",
       " '8050',\n",
       " '8051',\n",
       " '8052',\n",
       " '8053',\n",
       " '8054',\n",
       " '8056',\n",
       " '8060']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_matches = matches['matches']\n",
    "\n",
    "subject_keys = [k for k in int_matches.keys() if k.startswith('8')]\n",
    "subject_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "459016fc-30df-4cd6-b10a-4a3f558eb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1 dtype: object\n",
      "First 10 values: ['8022', '8001', '8002', '8003', '8004', '8007', '8006', '8005', '8008', '8009']\n",
      "IDs in subject_keys but not in df col1 (0): []\n"
     ]
    }
   ],
   "source": [
    "# 1) Extract the “column 1” IDs properly:\n",
    "#    If `boost_ids` is a DataFrame:\n",
    "col1 = boost_ids\n",
    "\n",
    "# 2) Inspect its dtype and contents\n",
    "print(\"Column 1 dtype:\", col1.dtype)\n",
    "print(\"First 10 values:\", col1.head(10).tolist())\n",
    "\n",
    "# 3) Normalize to strings (and strip whitespace)\n",
    "#    If it’s a float dtype (e.g. 6022.0), cast to int first:\n",
    "if pd.api.types.is_float_dtype(col1):\n",
    "    col1 = col1.dropna().astype(int).astype(str)\n",
    "else:\n",
    "    col1 = col1.astype(str)\n",
    "\n",
    "df_ids = [s.strip() for s in col1.tolist()]\n",
    "\n",
    "# 4) Also strip your subject_keys\n",
    "subject_keys = [s.strip() for s in subject_keys]\n",
    "\n",
    "# 5) Now do a set difference\n",
    "missing = sorted(set(subject_keys) - set(df_ids))\n",
    "print(f\"IDs in subject_keys but not in df col1 ({len(missing)}):\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ebcdbe9-5ac5-45d4-b87f-8d2f35cde086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In list only:    []\n",
      "In series only:  ['8007', '8031', '8055', '8025', '8041', '8013', '8029', '8058', '8010', '8033', '8043', '8034', '8045', '8028', '8057', '8009', '8059', '8061']\n"
     ]
    }
   ],
   "source": [
    "# 1) Normalize both to sets of strings\n",
    "boost_set   = set(boost_ids.astype(str))\n",
    "subject_set = set(subject_keys)\n",
    "\n",
    "# 2a) IDs in the list but NOT in the Series\n",
    "missing_in_series = list(subject_set - boost_set)\n",
    "print(\"In list only:   \", missing_in_series)\n",
    "\n",
    "# 2b) IDs in the Series but NOT in the list\n",
    "missing_in_list   = list(boost_set - subject_set)\n",
    "print(\"In series only: \", missing_in_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f652b-a5f1-476c-ae1b-87278a8f7107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
